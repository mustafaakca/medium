<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LangChain Core: Understanding langchain_core.messages</title>
</head>
<body>
    <h1>LangChain Core: Understanding <code>langchain_core.messages</code> for Message Management</h1>

    <p>When building AI-powered chat applications and tools, message management is one of the most critical aspects to consider. The <code>langchain_core.messages</code> module, a part of the LangChain framework, is designed to make managing interactions between humans and AI more flexible and customizable. In this article, we’ll explore the <code>langchain_core.messages</code> module, its key classes, practical use cases, and insights into how <code>ToolMessage</code> and <code>FunctionMessage</code> interact with external tools or internal logic.</p>

    <h2>What is LangChain Core?</h2>
    <p>LangChain is a powerful framework for integrating language models (LLMs) into various applications. It allows developers to chain data, integrate tools, and manage message exchanges in a modular and scalable way. The <code>langchain_core.messages</code> module specifically focuses on handling messages, making it essential for building chatbots, virtual assistants, or other interactive AI-driven applications.</p>

    <h2>The <code>langchain_core.messages</code> Module</h2>
    <p>This module provides classes that represent and manage the flow of messages between humans and AI. These messages serve as the backbone for interactions with LLMs.</p>

    <h2>Key Classes</h2>
    <ul>
        <li><b><code>HumanMessage</code></b>: Represents messages sent from a human to the AI. Allows customization of content, context, and optional metadata.</li>
        <li><b><code>SystemMessage</code></b>: Defines instructions for the model, such as setting its behavior (e.g., "Act as a helpful assistant.").</li>
        <li><b><code>ChatMessage</code></b>: A generic class that can represent any type of message (human, AI, or system).</li>
        <li><b><code>ToolMessage</code></b>: Used to interact with external tools, such as APIs or databases.</li>
        <li><b><code>FunctionMessage</code></b>: Handles dynamic function calls for specialized tasks.</li>
    </ul>

    <h2>HumanMessage vs. ChatMessage</h2>
    <p>Both <code>HumanMessage</code> and <code>ChatMessage</code> are used to represent user inputs, but they serve different purposes based on <b>specificity</b> and <b>flexibility</b>:</p>

    <table>
        <thead>
            <tr>
                <th>Aspect</th>
                <th><code>HumanMessage</code></th>
                <th><code>ChatMessage</code></th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><b>Purpose</b></td>
                <td>Specifically for messages sent by humans.</td>
                <td>A generic class for all types of messages in a chat.</td>
            </tr>
            <tr>
                <td><b>Message Source</b></td>
                <td>Always human-originating.</td>
                <td>Can represent messages from humans, AI, or systems.</td>
            </tr>
            <tr>
                <td><b>Flexibility</b></td>
                <td>More specialized and constrained.</td>
                <td>More flexible, allowing a unified format for mixed chats.</td>
            </tr>
            <tr>
                <td><b>Type Parameter</b></td>
                <td>Implicitly <code>"human"</code>.</td>
                <td>Explicitly requires <code>type</code> to specify the message source.</td>
            </tr>
            <tr>
                <td><b>Best Use Case</b></td>
                <td>Managing user-specific input in workflows.</td>
                <td>Managing full conversational threads with multiple message types.</td>
            </tr>
        </tbody>
    </table>

    <h3>Examples: HumanMessage vs. ChatMessage</h3>
    <p><b>Using <code>HumanMessage</code>:</b></p>
    <pre><code>from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="What is the weather today?")
]

# Simulate model response
model = ...  # Replace with your model
response = model.invoke(messages)
print(response)
    </code></pre>

    <p><b>Using <code>ChatMessage</code>:</b></p>
    <pre><code>from langchain_core.messages import ChatMessage

messages = [
    ChatMessage(content="You are a helpful assistant.", type="system"),
    ChatMessage(content="What is the weather today?", type="human"),
    ChatMessage(content="The weather today is sunny with a high of 25°C.", type="ai")
]

# Manage the entire chat thread
for message in messages:
    print(f"{message.type.capitalize()}: {message.content}")
    </code></pre>

    <h2>Key Differences Between ToolMessage and FunctionMessage</h2>
    <p>While both <code>ToolMessage</code> and <code>FunctionMessage</code> are designed to invoke external processes or operations, they serve distinct purposes. Here's a comparison:</p>

    <table>
        <thead>
            <tr>
                <th>Aspect</th>
                <th><code>ToolMessage</code></th>
                <th><code>FunctionMessage</code></th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><b>Use Case</b></td>
                <td>Represents calls to external tools (APIs, databases).</td>
                <td>Represents calls to specific Python functions.</td>
            </tr>
            <tr>
                <td><b>Purpose</b></td>
                <td>Integration with external systems or services.</td>
                <td>Internal logic or computation tasks within the application.</td>
            </tr>
            <tr>
                <td><b>Input Parameters</b></td>
                <td>Passed via <code>additional_kwargs</code>.</td>
                <td>Passed via <code>additional_kwargs</code>.</td>
            </tr>
            <tr>
                <td><b>Definition Location</b></td>
                <td>Tool logic is often external (e.g., API endpoints).</td>
                <td>Function logic is internal, implemented in the application.</td>
            </tr>
            <tr>
                <td><b>Examples</b></td>
                <td>Fetching weather data, querying stock prices.</td>
                <td>Solving equations, calculating sums.</td>
            </tr>
        </tbody>
    </table>

    <h2>Using ToolMessage</h2>
    <p><b>What is <code>ToolMessage</code>?</b></p>
    <p><code>ToolMessage</code> is designed to represent a call to an external tool or resource, such as:</p>
    <ul>
        <li>APIs (e.g., weather APIs, translation APIs).</li>
        <li>Databases (querying or retrieving data).</li>
        <li>Any custom Python functions that provide additional functionality.</li>
    </ul>

    <h3>Example: Using a Tool for Weather Information</h3>
    <pre><code>from langchain_core.messages import ToolMessage

# ToolMessage definition
messages = [
    ToolMessage(
        content="weather_api_call",
        additional_kwargs={
            "location": "Toronto",
            "description": "Fetches the current weather for the specified location."
        }
    )
]

# The actual tool (defined elsewhere in the application)
def weather_api_call(location):
    # Simulated API response
    return f"The current weather in {location} is sunny, 25°C."

# Extract parameters and invoke the tool
location = messages[0].additional_kwargs["location"]
response = weather_api_call(location)

print(f"Location: {location}")
print(f"Weather Info: {response}")
    </code></pre>

    <h2>Using FunctionMessage</h2>
    <p><b>What is <code>FunctionMessage</code>?</b></p>
    <p><code>FunctionMessage</code> is used for calling internal functions within the application. It provides:</p>
    <ul>
        <li><b>The function name</b> (<code>content</code>).</li>
        <li><b>Arguments or parameters</b> for the function (<code>additional_kwargs</code>).</li>
        <li><b>Optional descriptions</b> to document the function's purpose.</li>
    </ul>

    <h3>Example: Solving a Quadratic Equation</h3>
    <pre><code>from langchain_core.messages import FunctionMessage

# Define the FunctionMessage
messages = [
    FunctionMessage(
        content="solve_equation",
        additional_kwargs={
            "args": ["x^2 - 4x + 4 = 0"],
            "description": "This function solves quadratic equations."
        }
    )
]

# The actual function logic (defined elsewhere in the application)
def solve_equation(equation):
    # Simulating equation solving
    return "x = 2"

# Extract parameters and call the function
equation = messages[0].additional_kwargs["args"][0]
solution = solve_equation(equation)

print(f"Equation: {equation}")
print(f"Solution: {solution}")
    </code></pre>

    <h2>Conclusion</h2>
    <p>The <code>langchain_core.messages</code> module offers powerful and flexible tools for managing human-AI interactions, integrating external tools, and running internal logic. By understanding the differences between <code>HumanMessage</code>, <code>ChatMessage</code>, <code>ToolMessage</code>, and <code>FunctionMessage</code>, developers can build workflows tailored to their applications' unique needs.</p>

    <h3>Key Takeaways:</h3>
    <ul>
        <li>Use <code>HumanMessage</code> for human-specific interactions.</li>
        <li>Use <code>ChatMessage</code> for managing conversations involving multiple message sources.</li>
        <li>Use <code>ToolMessage</code> for external tool integrations (e.g., APIs).</li>
        <li>Use <code>FunctionMessage</code> for internal computations or logic.</li>
    </ul>

    <p><b>What tools or functions would you integrate into your workflows?</b> Have you tried using <code>ToolMessage</code> or <code>FunctionMessage</code> in your projects? Let us know your thoughts in the comments below!</p>
</body>
</html>
